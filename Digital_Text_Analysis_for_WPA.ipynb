{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOakfoG5jDfgpc4uitVZwF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Digital-Text-Analysis-for-WPA/blob/main/Digital_Text_Analysis_for_WPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digital Text Analysis for WPA\n",
        "A pipeline for examining student essays computationally for the purposes of writing program assessment.\n",
        "\n",
        "Updated February 2023\n",
        "\n",
        "Questions? Contact megan.kane@temple.edu"
      ],
      "metadata": {
        "id": "HuuInxdvV-Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages and Upload Files"
      ],
      "metadata": {
        "id": "AR1C6TN6Yjc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install os and glob\n",
        "import glob \n",
        "import os\n",
        "\n",
        "#Install pandas\n",
        "import pandas as pd\n",
        "\n",
        "#Install regular expressions\n",
        "import re"
      ],
      "metadata": {
        "id": "M773w-7EWKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8ekF5EmV7wh"
      },
      "outputs": [],
      "source": [
        "#Upload dataframe with papers and scores\n",
        "#Pipeline for associating & cleaning essays and grades: https://github.com/mkane968/Text-Mining-with-Student-Papers/blob/main/notebooks/Text%20Mining%20Student%20Essays%2012-2022%20(Jupyter%20Notebook).ipynb\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment Texts into Paragraphs"
      ],
      "metadata": {
        "id": "fKu1_zwIXsgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform csv to dataframe\n",
        "paragraphs_df = pd.read_csv('essays_and_scores.csv', index_col=0)\n",
        "\n",
        "#Add ID and score in one column\n",
        "paragraphs_df['Score_ID'] = 'Score: ' + paragraphs_df['Score'].astype(str) + ', ID: ' + paragraphs_df['ID'].astype(str)\n",
        "\n",
        "#Check new df\n",
        "paragraphs_df.head()"
      ],
      "metadata": {
        "id": "8cilZzCMXg-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count number of paragraphs in each text\n",
        "paragraph_counts = paragraphs_df['Text_Newlines'].str.count(r'\\n')\n",
        "paragraph_counts\n",
        "\n",
        "#Append paragraphs counts to dataframe\n",
        "paragraphs_df[\"Paragraph_Counts\"] = paragraph_counts\n",
        "paragraphs_df"
      ],
      "metadata": {
        "id": "2px_v9ibXxQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make new cell each time new paragraph starts \n",
        "new = paragraphs_df[\"Text_Newlines\"].str.split(r'\\n', expand = True).set_index(paragraphs_df['Score_ID'])\n",
        "\n",
        "#Flatten dataframe so each chapter is on own row, designated by book and chapter \n",
        "paragraphs_df = new.stack().reset_index()\n",
        "paragraphs_df.columns = [\"Score_ID\", \"Paragraph\", \"Text\"]\n",
        "\n",
        "#Split score and ID back to own columns\n",
        "paragraphs_df[['Score','ID']] = paragraphs_df.Score_ID.str.split(\", \",expand=True)\n",
        "paragraphs_df['Score'] = paragraphs_df['Score'].map(lambda x: x.lstrip('Score: '))\n",
        "paragraphs_df['ID'] = paragraphs_df['ID'].map(lambda x: x.lstrip('ID: '))\n",
        "paragraphs_df['Score_ID_Paragraph'] = 'Score:_' + paragraphs_df['Score'].astype(str) + '_ID:_' + paragraphs_df['ID'].astype(str) + '_Paragraph:_' + paragraphs_df['Paragraph'].astype(str)\n",
        "paragraphs_df"
      ],
      "metadata": {
        "id": "jXDKq8-vYPdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Clean paragraphs\n",
        "##Filter out paragraphs with 5 or less words (headers)\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.split().str.len().lt(10)]\n",
        "\n",
        "## Filter out paragraphs containing \"http://\", \"doi:\" , \"https://\" and \"://www\" (Works Cited citations)\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"http://\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"https://\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"://www\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"www.\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\".com/\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"Vol.\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"doi:\")]\n",
        "\n",
        "paragraphs_df"
      ],
      "metadata": {
        "id": "Lqh-go5BYRoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep only score/id/paragraph and texts\n",
        "paragraphs_full = paragraphs_df[['Score_ID_Paragraph', 'Text']].copy()\n",
        "\n",
        "#Download dataframe with all paragraphs\n",
        "paragraphs_full.to_csv('paragraphs_full.csv') \n",
        "files.download('paragraphs_full.csv')"
      ],
      "metadata": {
        "id": "4-6veiLIeAl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keep Only Paragraphs with Rhetorical Terminology"
      ],
      "metadata": {
        "id": "gLlJd6OqYdcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Set up new dataframe for keyword frequency counts\n",
        "rhetorical_keywords_paragraphs_df = paragraphs_df[['Score_ID_Paragraph', 'Text']].copy()\n",
        "\n",
        "#Count number of occurences of rhetorical terms in each paper\n",
        "pathos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('pathos')\n",
        "ethos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('ethos')\n",
        "logos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('logos')\n",
        "audience_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('audience')\n",
        "context_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('context')\n",
        "purpose_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('purpose')\n",
        "author_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('author')\n",
        "exigency_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('exigency')\n",
        "appeal_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('appeal')\n",
        "\n",
        "#Append each count to the dataframe\n",
        "rhetorical_keywords_paragraphs_df['Pathos_Counts'] = pathos_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Ethos_Counts\"] = ethos_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Logos_Counts\"] = logos_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Audience_Counts\"] = audience_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Context_Counts\"] = context_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Purpose_Counts\"] = purpose_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Author_Counts\"] = author_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Exigency_Counts\"] = exigency_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Appeal_Counts\"] = appeal_counts\n",
        "\n",
        "\n",
        "#Get sum of all term usages\n",
        "rhetorical_terms = ['Pathos_Counts', 'Ethos_Counts', 'Logos_Counts', 'Audience_Counts', 'Context_Counts', 'Purpose_Counts', 'Author_Counts', 'Exigency_Counts', 'Appeal_Counts']\n",
        "rhetorical_keywords_paragraphs_df['Sum_Terms'] = rhetorical_keywords_paragraphs_df[rhetorical_terms].sum(axis=1)\n",
        "\n",
        "#Check dataframe\n",
        "rhetorical_keywords_paragraphs_df"
      ],
      "metadata": {
        "id": "R6PHdj7dYnAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all rows with no rhetorical terms\n",
        "rhetorical_keywords_paragraphs_df = rhetorical_keywords_paragraphs_df[rhetorical_keywords_paragraphs_df.Sum_Terms > 0]\n",
        "\n",
        "rhetorical_keywords_paragraphs_df"
      ],
      "metadata": {
        "id": "p4TzNoNKZkLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep only score/id/paragraph and text column\n",
        "rhetorical_paras = rhetorical_keywords_paragraphs_df[['Score_ID_Paragraph', 'Text']].copy()\n",
        "rhetorical_paras"
      ],
      "metadata": {
        "id": "0nMa8rAlZrn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download dataframe with scores and rhetorical terminology paragraphs\n",
        "rhetorical_paras.to_csv('rhetorical_paras.csv') \n",
        "files.download('rhetorical_paras.csv')"
      ],
      "metadata": {
        "id": "4yNQxBQqckgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download zip file with rhetorical terminology paragraphs named by score\n",
        "#Add each text to a new list called paragraphs\n",
        "rhetorical_paragraphs = []\n",
        "for row in rhetorical_paras['Text'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    rhetorical_paragraphs.append(row_string)\n",
        "\n",
        "#Add filenames to list\n",
        "filenames = []\n",
        "for row in rhetorical_paras['Score_ID_Paragraph'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    filenames.append(row_string)\n",
        "\n",
        "filenames[1]\n",
        "\n",
        "#Make new directory to store text files\n",
        "!mkdir rhetorical_paragraphs\n",
        "\n",
        "#Write texts to files\n",
        "n = 0\n",
        "for item in rhetorical_paragraphs:\n",
        "  f = open(\"rhetorical_paragraphs/\" + filenames[n] +  '.txt','w')\n",
        "  n= n+1\n",
        "  f.write(item)\n",
        "  f.close()\n",
        "  \n",
        "#Zip text files in folder\n",
        "!zip -r rhetorical_paragraphs.zip rhetorical_paragraphs\n",
        "\n",
        "#Download file to zip folder to run through DocuScope\n",
        "files.download('rhetorical_paragraphs.zip')\n"
      ],
      "metadata": {
        "id": "3_7aCDr3YnDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keep Only Paragraphs with Citation Markers"
      ],
      "metadata": {
        "id": "18k7bo2ydEv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get any text inside parentheticals and count of parentheticals and append to dataframe\n",
        "#https://stackoverflow.com/questions/24696715/regex-for-match-parentheses-in-python\n",
        "parentheticals = r'(?<=\\().*?(?=\\))'\n",
        "\n",
        "#Add new list for parenthetical citations\n",
        "parenthetical_matches = []\n",
        "parenthetical_counts = []\n",
        "\n",
        "#Find all occurences of parenthetical citations in each paragraph of each text\n",
        "citation_df = paragraphs_df[['Score_ID_Paragraph', 'Text']].copy()\n",
        "for text in citation_df['Text']:\n",
        "  matches = re.findall(parentheticals, text)\n",
        "  parenthetical_matches.append(matches)\n",
        "  parenthetical_counts.append(len(matches))\n",
        "\n",
        "#Make new column counting all appearances of parentheticals\n",
        "citation_df[\"Parentheticals\"] = parenthetical_matches\n",
        "citation_df['Parenthetical_Counts'] = parenthetical_counts\n",
        "\n",
        "citation_df\n"
      ],
      "metadata": {
        "id": "kaUSFxqVYnGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all rows with no parenthetical terms\n",
        "citation_df_no_blanks = citation_df[citation_df.Parenthetical_Counts > 0]\n",
        "citation_df_no_blanks"
      ],
      "metadata": {
        "id": "szDs45sqdRpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep only score/id/paragraph and text column\n",
        "citation_paras = citation_df_no_blanks[['Score_ID_Paragraph', 'Text']].copy()\n",
        "citation_paras"
      ],
      "metadata": {
        "id": "SjAa6HBEYnIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download dataframe with scores and citation paragraphs\n",
        "citation_paras.to_csv('citation_paras.csv') \n",
        "files.download('citation_paras.csv')"
      ],
      "metadata": {
        "id": "A0HNY_d_YnLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download zip file with rhetorical terminology paragraphs named by score\n",
        "#Add each text to a new list called paragraphs\n",
        "citation_paragraphs = []\n",
        "for row in citation_paras['Text'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    citation_paragraphs.append(row_string)\n",
        "\n",
        "#Add filenames to list\n",
        "filenames = []\n",
        "for row in citation_paras['Score_ID_Paragraph'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    filenames.append(row_string)\n",
        "\n",
        "filenames[1]\n",
        "\n",
        "#Make new directory to store text files\n",
        "!mkdir citation_paragraphs\n",
        "\n",
        "#Write texts to files\n",
        "n = 0\n",
        "for item in citation_paragraphs:\n",
        "  f = open(\"citation_paragraphs/\" + filenames[n] +  '.txt','w')\n",
        "  n= n+1\n",
        "  f.write(item)\n",
        "  f.close()\n",
        "  \n",
        "#Zip text files in folder\n",
        "!zip -r citation_paragraphs.zip citation_paragraphs\n",
        "\n",
        "#Download file to zip folder to run through DocuScope\n",
        "files.download('citation_paragraphs.zip')\n"
      ],
      "metadata": {
        "id": "SudH80LOYbjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}