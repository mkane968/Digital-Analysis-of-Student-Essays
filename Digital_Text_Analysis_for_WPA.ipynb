{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6c5LKBMjL2GdU8dfvs9nY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Digital-Text-Analysis-for-WPA/blob/main/Digital_Text_Analysis_for_WPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digital Text Analysis for WPA\n",
        "A pipeline for examining student essays computationally for the purposes of writing program assessment.\n",
        "\n",
        "Updated February 2023\n",
        "\n",
        "Questions? Contact megan.kane@temple.edu"
      ],
      "metadata": {
        "id": "HuuInxdvV-Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages and Upload Files"
      ],
      "metadata": {
        "id": "AR1C6TN6Yjc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install os and glob\n",
        "import glob \n",
        "import os\n",
        "\n",
        "#Install pandas\n",
        "import pandas as pd\n",
        "\n",
        "#Install regular expressions\n",
        "import re\n",
        "\n",
        "#Import files to upload text and csv files to drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "M773w-7EWKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment Texts into Paragraphs"
      ],
      "metadata": {
        "id": "fKu1_zwIXsgX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8ekF5EmV7wh"
      },
      "outputs": [],
      "source": [
        "#Upload dataframe with papers and scores\n",
        "#Pipeline for associating & cleaning essays and grades: https://github.com/mkane968/Text-Mining-with-Student-Papers/blob/main/notebooks/Text%20Mining%20Student%20Essays%2012-2022%20(Jupyter%20Notebook).ipynb\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform csv to dataframe\n",
        "paragraphs_df = pd.read_csv('essays_and_scores.csv', index_col=0)\n",
        "\n",
        "#Add ID and score in one column\n",
        "paragraphs_df['Score_ID'] = 'Score: ' + paragraphs_df['Score'].astype(str) + ', ID: ' + paragraphs_df['ID'].astype(str)\n",
        "\n",
        "#Check new df\n",
        "paragraphs_df.head()"
      ],
      "metadata": {
        "id": "8cilZzCMXg-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count number of paragraphs in each text\n",
        "paragraph_counts = paragraphs_df['Text_Newlines'].str.count(r'\\n')\n",
        "paragraph_counts\n",
        "\n",
        "#Append paragraphs counts to dataframe\n",
        "paragraphs_df[\"Paragraph_Counts\"] = paragraph_counts\n",
        "paragraphs_df"
      ],
      "metadata": {
        "id": "2px_v9ibXxQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make new cell each time new paragraph starts \n",
        "new = paragraphs_df[\"Text_Newlines\"].str.split(r'\\n', expand = True).set_index(paragraphs_df['Score_ID'])\n",
        "\n",
        "#Flatten dataframe so each chapter is on own row, designated by book and chapter \n",
        "paragraphs_df = new.stack().reset_index()\n",
        "paragraphs_df.columns = [\"Score_ID\", \"Paragraph\", \"Text\"]\n",
        "\n",
        "#Split score and ID back to own columns\n",
        "paragraphs_df[['Score','ID']] = paragraphs_df.Score_ID.str.split(\", \",expand=True)\n",
        "paragraphs_df['Score'] = paragraphs_df['Score'].map(lambda x: x.lstrip('Score: '))\n",
        "paragraphs_df['ID'] = paragraphs_df['ID'].map(lambda x: x.lstrip('ID: '))\n",
        "paragraphs_df['Score_ID_Paragraph'] = 'Score:_' + paragraphs_df['Score'].astype(str) + '_ID:_' + paragraphs_df['ID'].astype(str) + '_Paragraph:_' + paragraphs_df['Paragraph'].astype(str)\n",
        "paragraphs_df"
      ],
      "metadata": {
        "id": "jXDKq8-vYPdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Clean paragraphs\n",
        "##Filter out paragraphs with 5 or less words (headers)\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.split().str.len().lt(10)]\n",
        "\n",
        "## Filter out paragraphs containing \"http://\", \"doi:\" , \"https://\" and \"://www\" (Works Cited citations)\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"http://\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"https://\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"://www\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"www.\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\".com/\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"Vol.\")]\n",
        "\n",
        "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"doi:\")]\n",
        "\n",
        "paragraphs_df"
      ],
      "metadata": {
        "id": "Lqh-go5BYRoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep only score/id/paragraph and texts\n",
        "paragraphs_full = paragraphs_df[['Score_ID_Paragraph', 'Text']].copy()\n",
        "\n",
        "#Download dataframe with all paragraphs\n",
        "paragraphs_full.to_csv('paragraphs_full.csv') \n",
        "files.download('paragraphs_full.csv')"
      ],
      "metadata": {
        "id": "4-6veiLIeAl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keep Only Paragraphs with Rhetorical Terminology"
      ],
      "metadata": {
        "id": "gLlJd6OqYdcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Set up new dataframe for keyword frequency counts\n",
        "rhetorical_keywords_paragraphs_df = paragraphs_df[['Score','Score_ID_Paragraph', 'Text']].copy()\n",
        "\n",
        "#Count number of occurences of rhetorical terms in each paper\n",
        "pathos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('pathos')\n",
        "ethos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('ethos')\n",
        "logos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('logos')\n",
        "audience_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('audience')\n",
        "context_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('context')\n",
        "purpose_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('purpose')\n",
        "author_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('author')\n",
        "exigency_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('exigency')\n",
        "appeal_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('appeal')\n",
        "\n",
        "#Append each count to the dataframe\n",
        "rhetorical_keywords_paragraphs_df['Pathos_Counts'] = pathos_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Ethos_Counts\"] = ethos_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Logos_Counts\"] = logos_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Audience_Counts\"] = audience_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Context_Counts\"] = context_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Purpose_Counts\"] = purpose_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Author_Counts\"] = author_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Exigency_Counts\"] = exigency_counts\n",
        "rhetorical_keywords_paragraphs_df[\"Appeal_Counts\"] = appeal_counts\n",
        "\n",
        "\n",
        "#Get sum of all term usages\n",
        "rhetorical_terms = ['Pathos_Counts', 'Ethos_Counts', 'Logos_Counts', 'Audience_Counts', 'Context_Counts', 'Purpose_Counts', 'Author_Counts', 'Exigency_Counts', 'Appeal_Counts']\n",
        "rhetorical_keywords_paragraphs_df['Sum_Terms'] = rhetorical_keywords_paragraphs_df[rhetorical_terms].sum(axis=1)\n",
        "\n",
        "#Check dataframe\n",
        "rhetorical_keywords_paragraphs_df"
      ],
      "metadata": {
        "id": "R6PHdj7dYnAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all rows with no rhetorical terms\n",
        "rhetorical_keywords_paragraphs_df = rhetorical_keywords_paragraphs_df[rhetorical_keywords_paragraphs_df.Sum_Terms > 0]\n",
        "\n",
        "rhetorical_keywords_paragraphs_df"
      ],
      "metadata": {
        "id": "p4TzNoNKZkLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep only score/id/paragraph and text column\n",
        "rhetorical_paras = rhetorical_keywords_paragraphs_df[['Score_ID_Paragraph', 'Text']].copy()\n",
        "rhetorical_paras"
      ],
      "metadata": {
        "id": "0nMa8rAlZrn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download dataframe with scores and rhetorical terminology paragraphs\n",
        "rhetorical_paras.to_csv('rhetorical_paras.csv') \n",
        "files.download('rhetorical_paras.csv')"
      ],
      "metadata": {
        "id": "4yNQxBQqckgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download zip file with rhetorical terminology paragraphs named by score\n",
        "#Add each text to a new list called paragraphs\n",
        "rhetorical_paragraphs = []\n",
        "for row in rhetorical_paras['Text'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    rhetorical_paragraphs.append(row_string)\n",
        "\n",
        "#Add filenames to list\n",
        "filenames = []\n",
        "for row in rhetorical_paras['Score_ID_Paragraph'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    filenames.append(row_string)\n",
        "\n",
        "filenames[1]\n",
        "\n",
        "#Make new directory to store text files\n",
        "!mkdir rhetorical_paragraphs\n",
        "\n",
        "#Write texts to files\n",
        "n = 0\n",
        "for item in rhetorical_paragraphs:\n",
        "  f = open(\"rhetorical_paragraphs/\" + filenames[n] +  '.txt','w')\n",
        "  n= n+1\n",
        "  f.write(item)\n",
        "  f.close()\n",
        "  \n",
        "#Zip text files in folder\n",
        "!zip -r rhetorical_paragraphs.zip rhetorical_paragraphs\n",
        "\n",
        "#Download file to zip folder to run through DocuScope\n",
        "files.download('rhetorical_paragraphs.zip')\n"
      ],
      "metadata": {
        "id": "3_7aCDr3YnDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keep Only Paragraphs with Citation Markers"
      ],
      "metadata": {
        "id": "18k7bo2ydEv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get any text inside parentheticals and count of parentheticals and append to dataframe\n",
        "#https://stackoverflow.com/questions/24696715/regex-for-match-parentheses-in-python\n",
        "parentheticals = r'(?<=\\().*?(?=\\))'\n",
        "\n",
        "#Add new list for parenthetical citations\n",
        "parenthetical_matches = []\n",
        "parenthetical_counts = []\n",
        "\n",
        "#Find all occurences of parenthetical citations in each paragraph of each text\n",
        "citation_df = paragraphs_df[['Score','Score_ID_Paragraph', 'Text']].copy()\n",
        "for text in citation_df['Text']:\n",
        "  matches = re.findall(parentheticals, text)\n",
        "  parenthetical_matches.append(matches)\n",
        "  parenthetical_counts.append(len(matches))\n",
        "\n",
        "#Make new column counting all appearances of parentheticals\n",
        "citation_df[\"Parentheticals\"] = parenthetical_matches\n",
        "citation_df['Parenthetical_Counts'] = parenthetical_counts\n",
        "\n",
        "citation_df\n"
      ],
      "metadata": {
        "id": "kaUSFxqVYnGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all rows with no parenthetical terms\n",
        "citation_df_no_blanks = citation_df[citation_df.Parenthetical_Counts > 0]\n",
        "citation_df_no_blanks"
      ],
      "metadata": {
        "id": "szDs45sqdRpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep only score/id/paragraph and text column\n",
        "citation_paras = citation_df_no_blanks[['Score_ID_Paragraph', 'Text']].copy()\n",
        "citation_paras"
      ],
      "metadata": {
        "id": "SjAa6HBEYnIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download dataframe with scores and citation paragraphs\n",
        "citation_paras.to_csv('citation_paras.csv') \n",
        "files.download('citation_paras.csv')"
      ],
      "metadata": {
        "id": "A0HNY_d_YnLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download zip file with rhetorical terminology paragraphs named by score\n",
        "#Add each text to a new list called paragraphs\n",
        "citation_paragraphs = []\n",
        "for row in citation_paras['Text'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    citation_paragraphs.append(row_string)\n",
        "\n",
        "#Add filenames to list\n",
        "filenames = []\n",
        "for row in citation_paras['Score_ID_Paragraph'].items():\n",
        "    row_string = (str(row[1]))\n",
        "    filenames.append(row_string)\n",
        "\n",
        "filenames[1]\n",
        "\n",
        "#Make new directory to store text files\n",
        "!mkdir citation_paragraphs\n",
        "\n",
        "#Write texts to files\n",
        "n = 0\n",
        "for item in citation_paragraphs:\n",
        "  f = open(\"citation_paragraphs/\" + filenames[n] +  '.txt','w')\n",
        "  n= n+1\n",
        "  f.write(item)\n",
        "  f.close()\n",
        "  \n",
        "#Zip text files in folder\n",
        "!zip -r citation_paragraphs.zip citation_paragraphs\n",
        "\n",
        "#Download file to zip folder to run through DocuScope\n",
        "files.download('citation_paragraphs.zip')\n"
      ],
      "metadata": {
        "id": "SudH80LOYbjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Analyses with Rhetorical and Citation Terms"
      ],
      "metadata": {
        "id": "Us7blc5eiyfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bring down rhetorical paras dataframe with term counts\n",
        "rhet_calculations_df = rhetorical_keywords_paragraphs_df.copy()\n",
        "rhet_calculations_df.head()"
      ],
      "metadata": {
        "id": "UJdwwh-mwWOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Add term counts from Voyant\n",
        "#Count number of times the words \"article\" and \"articles\" appear in each text\n",
        "feel_counts = rhet_calculations_df['Text'].str.count('feel')\n",
        "articles_counts = rhet_calculations_df['Text'].str.count('understand')\n",
        "element_counts = rhet_calculations_df['Text'].str.count('element')\n",
        "rhetorical_counts = rhet_calculations_df['Text'].str.count('rhetorical')\n",
        "\n",
        "\n",
        "#Append each count to the dataframe\n",
        "rhet_calculations_df['Feel_Counts'] = feel_counts\n",
        "rhet_calculations_df[\"Understand_Counts\"] = articles_counts\n",
        "rhet_calculations_df[\"Element_Counts\"] = articles_counts\n",
        "rhet_calculations_df[\"Rhetorical_Counts\"] = articles_counts\n",
        "\n",
        "\n",
        "#Get sum of all term usages\n",
        "rhetorical_terms = ['Pathos_Counts', 'Ethos_Counts', 'Logos_Counts', 'Audience_Counts', 'Context_Counts', 'Purpose_Counts', 'Author_Counts', 'Exigency_Counts', 'Appeal_Counts', 'Feel_Counts', 'Understand_Counts', 'Element_Counts', 'Rhetorical_Counts']\n",
        "rhet_calculations_df['Sum_Terms'] = rhet_calculations_df[rhetorical_terms].sum(axis=1)\n",
        "\n",
        "rhet_calculations_df.head()"
      ],
      "metadata": {
        "id": "_kLCeRHq3P8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart average use of each term across two paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(rhet_calculations_df, x=\"Score\", y='Sum_Terms', barmode='group')\n",
        "fig.update_layout(title_text='Usage of Rhetorical Terms in Each Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bjGmMV313FnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if amount of all term usage is indicative of grade\n",
        "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create arrays of independent (x) and dependent (y) variables\n",
        "x = np.array(rhet_calculations_df['Score']).astype(float)\n",
        "y = np.array(rhet_calculations_df['Sum_Terms']).astype(float)\n",
        "\n",
        "#Return key values of linear regression\n",
        "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
        "\n",
        "result = stats.linregress(x, y)\n",
        "\n",
        "print(f\"R-squared for Number of Rhetorical Terms Used in Each Paragraph: {result.rvalue**2:}\")\n",
        "\n",
        "plt.plot(x, y, 'o', label='Student Essay Data', color = 'b')\n",
        "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
        "plt.xlabel(\"Paper Score\")\n",
        "plt.ylabel(\"Count of Rhetorical Terms Used\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E8c_2GeUwdk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bring down citation paras dataframe with term counts\n",
        "citation_calculations_df = citation_df_no_blanks.copy()\n",
        "citation_calculations_df.head()"
      ],
      "metadata": {
        "id": "HwWCO2rjyC6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if amount of all term usage is indicative of grade\n",
        "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create arrays of independent (x) and dependent (y) variables\n",
        "x = np.array(citation_calculations_df['Score']).astype(float)\n",
        "y = np.array(citation_calculations_df['Parenthetical_Counts']).astype(float)\n",
        "\n",
        "#Return key values of linear regression\n",
        "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
        "\n",
        "result = stats.linregress(x, y)\n",
        "\n",
        "print(f\"R-squared for Number of Parenthetical Citations Used in Each Paragraph: {result.rvalue**2:}\")\n",
        "\n",
        "plt.plot(x, y, 'o', label='Student Essay Data', color = 'g')\n",
        "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
        "plt.xlabel(\"Paper Score\")\n",
        "plt.ylabel(\"Count of Parenthetical Citations Used\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nlcGbQCliyBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count number of times the words \"article\" and \"articles\" appear in each text\n",
        "article_counts = citation_calculations_df['Text'].str.count('article')\n",
        "articles_counts = citation_calculations_df['Text'].str.count('articles')\n",
        "\n",
        "#Append each count to the dataframe\n",
        "citation_calculations_df['Article_Counts'] = article_counts\n",
        "citation_calculations_df[\"Articles_Counts\"] = articles_counts\n",
        "citation_calculations_df"
      ],
      "metadata": {
        "id": "L-ki0YZwy9Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart average use of each term across two paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(citation_calculations_df, x=\"Score\", y=[\"Articles_Counts\", \"Article_Counts\"], barmode='group')\n",
        "fig.update_layout(title_text='Usage of \"Article\" and \"Articles\" in Each Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "N8Rx5Gm4za2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if amount of articles term usage is indicative of grade\n",
        "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create arrays of independent (x) and dependent (y) variables\n",
        "x = np.array(citation_calculations_df['Score']).astype(float)\n",
        "y = np.array(citation_calculations_df['Articles_Counts']).astype(float)\n",
        "\n",
        "#Return key values of linear regression\n",
        "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
        "\n",
        "result = stats.linregress(x, y)\n",
        "\n",
        "print(f\"R-squared for Number of Times 'Articles' Is Used in Each Paragraph: {result.rvalue**2:}\")\n",
        "\n",
        "plt.plot(x, y, 'o', label='Student Essay Data', color = 'y')\n",
        "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
        "plt.xlabel(\"Paper Score\")\n",
        "plt.ylabel(\"Count of Term 'Articles' Used\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3Rqd8XCG16c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate DocuScope LAT Frequencies"
      ],
      "metadata": {
        "id": "m_6Gfzgkp6gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload citation paragraphs data from DocuScope\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "It95gs0tp6oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform csv to dataframe\n",
        "citation_docuscope_data = pd.read_csv('CLUSTER_N_citation_paragraphs 2.csv')\n",
        "\n",
        "#Regression: Citation vs. Grade\n",
        "#Separate out paragraph with score alone\n",
        "citation_docuscope_data[['ScoreTitle','Score', 'IDTitle', 'ID', 'ParagraphTitle', 'Paragraph']] = citation_docuscope_data.Filename.str.split(\"_\",expand=True)\n",
        "\n",
        "citation_docuscope_data['Score'] = citation_docuscope_data['Score'].map(lambda x: x.lstrip('Score: '))\n",
        "\n",
        "citation_docuscope_data.drop(['ScoreTitle','IDTitle', 'ID', 'ParagraphTitle', 'Paragraph'], axis=1, inplace=True)\n",
        "\n",
        "citation_docuscope_data"
      ],
      "metadata": {
        "id": "F3jq87stqTZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get average of each column\n",
        "citation_docuscope_avgs = citation_docuscope_data.mean().round(5)\n",
        "citation_docuscope_avgs = citation_docuscope_avgs.to_frame()\n",
        "citation_docuscope_avgs = citation_docuscope_avgs.iloc[2:]\n",
        "citation_docuscope_avgs = citation_docuscope_avgs.reset_index()\n",
        "citation_docuscope_avgs = citation_docuscope_avgs.rename(columns={'index': \"LATs\", 0: \"Average\"})\n",
        "#Sort from most to least frequent LATs\n",
        "citation_docuscope_avgs = citation_docuscope_avgs.sort_values(by=['Average'], ascending=False)\n",
        "citation_docuscope_avgs.head(20)"
      ],
      "metadata": {
        "id": "BYBxSdV25g8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart number of times most frequent LATs were used in each essay \n",
        "#Create bar graph\n",
        "#https://plotly.com/python/bar-charts/\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "#Chart average use of each term across two paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(citation_docuscope_data, x=\"Score\", y=[\"InformationGeneral\", \"Narrative\", \"Negative\", \"Description\", \"InformationExposition\"], barmode='group')\n",
        "fig.update_layout(title_text='Counts of Five Most Frequent LATs (on Average) in Each Citation Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "BE4mHcLKvElm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if amount of academic term term usage is indicative of grade\n",
        "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create arrays of independent (x) and dependent (y) variables\n",
        "x = np.array(citation_docuscope_data['Score']).astype(float)\n",
        "y = np.array(citation_docuscope_data['AcademicTerms']).astype(float)\n",
        "\n",
        "#Return key values of linear regression\n",
        "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
        "\n",
        "result = stats.linregress(x, y)\n",
        "\n",
        "print(f\"R-squared for Number of Academic Terms in Each Citation Paragraph: {result.rvalue**2:}\")\n",
        "\n",
        "plt.plot(x, y, 'o', label='Student Essay Data', color = 'g')\n",
        "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
        "plt.xlabel(\"Paper Score\")\n",
        "plt.ylabel(\"Academic Term Use Count\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "asETQ81A-3W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload rhetorical paragraph data from DocuScope\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "F4Ps0X50AdlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform csv to dataframe\n",
        "rhetorical_docuscope_data = pd.read_csv('CLUSTER_N_rhetorical_paragraphs.csv')\n",
        "\n",
        "#Regression: Citation vs. Grade\n",
        "#Separate out paragraph with score alone\n",
        "rhetorical_docuscope_data[['ScoreTitle','Score', 'IDTitle', 'ID', 'ParagraphTitle', 'Paragraph']] = rhetorical_docuscope_data.Filename.str.split(\"_\",expand=True)\n",
        "rhetorical_docuscope_data['Score'] = rhetorical_docuscope_data['Score'].map(lambda x: x.lstrip('Score: '))\n",
        "\n",
        "rhetorical_docuscope_data.drop(['ScoreTitle','IDTitle', 'ID', 'ParagraphTitle', 'Paragraph'], axis=1, inplace=True)\n",
        "\n",
        "rhetorical_docuscope_data"
      ],
      "metadata": {
        "id": "k-egJ6RxAior"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get average of each column\n",
        "rhetorical_docuscope_avgs = rhetorical_docuscope_data.mean().round(5)\n",
        "rhetorical_docuscope_avgs = rhetorical_docuscope_avgs.to_frame()\n",
        "rhetorical_docuscope_avgs = rhetorical_docuscope_avgs.iloc[2:]\n",
        "rhetorical_docuscope_avgs = rhetorical_docuscope_avgs.reset_index()\n",
        "rhetorical_docuscope_avgs = rhetorical_docuscope_avgs.rename(columns={'index': \"LATs\", 0: \"Average\"})\n",
        "#Sort from most to least frequent LATs\n",
        "rhetorical_docuscope_avgs = rhetorical_docuscope_avgs.sort_values(by=['Average'], ascending=False)\n",
        "rhetorical_docuscope_avgs.head(20)"
      ],
      "metadata": {
        "id": "z3efjtDFAisO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart number of times most frequent LATs were used in each essay \n",
        "#Create bar graph\n",
        "#https://plotly.com/python/bar-charts/\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "#Chart average use of each term across two paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(rhetorical_docuscope_data, x=\"Score\", y=[\"InformationGeneral\", \"Narrative\", \"Negative\", \"Description\", \"InformationExposition\"], barmode='group')\n",
        "fig.update_layout(title_text='Counts of Five Most Frequent LATs (on Average) in Each Rhetorical Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gVYEmUknHLfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sum LATs per score value (citations)\n",
        "sum_citations = citation_docuscope_data.groupby(\"Score\").mean()\n",
        "sum_citations.reset_index(inplace=True)\n",
        "sum_citations\n",
        "\n",
        "#Sum LATs per score value (rhetorical analysis)\n",
        "sum_rhetorical = rhetorical_docuscope_data.groupby(\"Score\").mean()\n",
        "sum_rhetorical.reset_index(inplace=True)\n",
        "sum_rhetorical\n",
        "\n",
        "#Combine sums of two columns into one dataframe\n",
        "sum_citations['Paragraph_Type'] = 'Citation'\n",
        "sum_rhetorical['Paragraph_Type'] = 'Rhetorical_Analysis'\n",
        "\n",
        "frames = [sum_citations, sum_rhetorical]\n",
        "\n",
        "result = pd.concat(frames)\n",
        "\n",
        "#Chart sum use of language type across both paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(result, x=\"Score\", y=\"AcademicTerms\", color='Paragraph_Type')\n",
        "fig.update_layout(title_text='Average Use of Academic Terms Language Across Paragraphs')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KiZUNAFYEKsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average LATs per score value (citations)\n",
        "avg_citations = docuscope_data.groupby(\"Score\").mean()\n",
        "avg_citations.reset_index(inplace=True)\n",
        "avg_citations\n",
        "\n",
        "#Average LATs per score value (rhetorical analysis)\n",
        "avg_rhetorical = docuscope_data2.groupby(\"Score\").mean()\n",
        "avg_rhetorical.reset_index(inplace=True)\n",
        "avg_rhetorical\n",
        "\n",
        "#combine averages of two columns into one dataframe\n",
        "avg_citations['Move'] = 'Citation'\n",
        "avg_rhetorical['Move'] = 'Rhetorical_Analysis'\n",
        "\n",
        "frames = [avg_citations, avg_rhetorical]\n",
        "\n",
        "result = pd.concat(frames)\n",
        "result\n",
        "\n",
        "#Chart average use of each term across two paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(result, x=\"Score\", y=\"Citation\", color='Move')\n",
        "fig.update_layout(title_text='Counts of Citation Language (on Average) in Each Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "BcnaN0I-Fgez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine averages of two columns into one dataframe\n",
        "avg_citations['Move'] = 'Citation'\n",
        "avg_rhetorical['Move'] = 'Rhetorical_Analysis'\n",
        "\n",
        "frames = [avg_citations, avg_rhetorical]\n",
        "\n",
        "result = pd.concat(frames)\n",
        "result"
      ],
      "metadata": {
        "id": "jBuzdbuGFlyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart average use of each term across two paragraph types\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(result, x=\"Score\", y=\"AcademicTerms\", color='Move')\n",
        "fig.update_layout(title_text='Counts of Metadiscourse Language (on Average) in Each Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YUy4gNmEDNwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart number of times most frequent LATs were used in each essay \n",
        "#Create bar graph\n",
        "#https://plotly.com/python/bar-charts/\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Academic Terms Counts', x=docuscope_data[\"Score\"], y=docuscope_data[\"AcademicTerms\"]),\n",
        "    go.Bar(name='Academic Terms Counts', x=docuscope_data2[\"Score\"], y=docuscope_data2[\"AcademicTerms\"]),\n",
        "\n",
        "])\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(title_text='Counts of Academic Term Language in Each Citation Paragraph')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8aFyFFaLAivI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}